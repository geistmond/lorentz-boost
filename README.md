Copyright: 武仁 TAKEMITSU, Zeami (武満世阿弥) "Brien"

The effects of the Higgs Field can be accounted for in terms of the Lorentz Boosts applying to wave function peaks and troughs.
Particle-like systems that interact with the Higgs Field in different ways carry mass differently, thus their wave functions ought 
to be different under the Lorentz transforms. "Boosts" and drag effects occur upon interaction with the Higgs Field.

There are supposed to be limits to how fast waves can travel, and this should apply below atomic scale, and that should be
consistent with Higgs-related observations.

"Reach out to Kyoto University with my Japanese name! My PhD might be a secret! I have pseudonyms!"

My family is from Japan. I was in Marseille processing trauma from the Foreign Legion where I served for 5 years.
I was losing sleep at night thinking about physics. War is physics. I used to do Physics before it was War.

How can I know if the peaks and troughs inside a quantum wave packet are traveling faster than light or not?
Other waves I have observed in nature are subject to physical constraints when they propagate information. It should be that way all over.
The waves shouldn't go FTL. No crest or trough can go faster than the standing wave body without it ceasing to be a wave.

But a wave packet is hard to examine. Still, why shouldn't I assume a wave function has an inertial frame of reference
that's subject to Lorenz boosts, blue shift / red shift, etc like any other stationary or traveling wave under relativity?

Limits on the propagation of information through light are limits on the behavior of information. I am speculating that this could lead to
a novel machine learning approach because the information contour of the universe is being modeled by learning machines. So that contour
might be as below, so above, in that conversation laws, FTL limits, etc can apply to all Joules, even information theoretic ones.

So if information is subject to Lorenz boosts, conversation laws, phenomena from statistical mechanics, etc then all of this must also
be subject to inertial frames of reference, because other waves exhibit the same phenomena, and this limits our information about the
state of physical systems.

Inertial frame of reference conservation laws applying to the behavior of traveling Quantum waves could potentially resolve certain
unanswered questions in Physics and even Mathematics.

Notion for ML application: The quantum wave packet function discretizes information and expands its representation into the complex domain. 
Maybe it can help map the contours of an entropic system to use the complex domain.

Machine learning systems are contour-modeling entropy wells for estimation. Rates of change model contours. Those are subject to FTL limits.

This combination of factors has potential to trap entropy in a way that's substantially different from neural nets.

For machine learning: 

Recursion and function optimizer are to be used until it predicts outputs from inputs well enough.

* Quantum wave function in complex domain, instead of visualizing it fills a variable-size matrix.
* Recursive Monadic Interpolation -- apply linear interpolator over continuously changing matrix size and track state in a monad. Optimize.
** Need a way to track the summarization and extrapolation of information like in different-sized layers within neural nets. Monad-consuming fuctors?
** We compute the contents of matrix dimensionalities using wave packets, currying / monads, and recursive information extraction.
** This will interpolate across different matrix dimensionalities, using that to make inferences from inputs. The matrices are squares.
** For example, the input is 100x100 but we want guesses at a smaller projection of the wave packet but the matrix is e x e dimensions or pi x pi dimensions.
* Predicted values are from contours in SVTs and other systems, this does contours and matrices.
** The contours and matrices are built around the behavior of quantum wave packets.
* Gonna leave the Schroeinger equation solution in this as a way to map information about inputs. 
** It creates a wave packet. That's the point of the visualizations.
** Wave packets are characteristic of systems. They model information already.

For physics: 

Need to determine if wave body compression within the packet is testable by e.g. perpendicular entangled lasers.
Need to include a basic mathematical proof for some people that a wave's peaks and troughs cannot go faster than its body can.
That seems simple but it absolutely implies an inertial frame of reference applying to the sine operator in a QM wave packet, not just
the sine operator applying to waves at sea, or kinetic waves in the air, or waves moving through solid matter. The crest and the peak
do not beat the wave body in reaching a point, they constitute its nature as a wave.

That this necessarily implies inertial frames of reference and Lorenz boosts applying to wave functions is called the 
Kyoto-Marseille Interpretation, because I must have to be stupid to propose a name for a physics interpretation.

Some physicists ignore that the Joule is used to measure both information and energy in a way that implies a system-dependent coefficient
that itself is frequently lower in highly entropic systems, but only to a point. J1 = K * J2, where J1 is information output out of a
computational system in Joules and J2 is energy input into the computer in Joules. Computational complexity is thermodynamic in nature.

So information propagating about this idea is going to be limited by the same physical constraints and can only occur in a seemingly
FTL way through wormholes / 'portals'. Necessarily an extension of this viewpoint about waves, should it be accepted, is the presumption
of compactified wormholes permitting information transfer in violation of known 'boosts' and conservation laws.
